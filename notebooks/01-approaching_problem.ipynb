{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_codebase.codebase import *\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Processing\n",
    "Approaching the problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOOK_PATH = r\"src\\books\\Physics9EM.pdf\"\n",
    "UNIT_VALUE_EXTRACTION_PROMPT = \"\"\"\n",
    "Following is a chunk of a student's book. Extract nothing but the value of the Unit number from it.\n",
    "Chunk: {page_chunk}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Path doesn't exist. Provided path: src\\books\\Physics9EM.pdf",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mload_single_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBOOK_PATH\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mD:\\Shaukat ali khan\\programming\\AI-Projects\\langchain-projects\\langchain_codebase\\langchain_codebase\\codebase.py:62\u001b[0m, in \u001b[0;36mload_single_pdf\u001b[1;34m(pdf_filepath, extract_images)\u001b[0m\n",
      "\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_single_pdf\u001b[39m(pdf_filepath: \u001b[38;5;28mstr\u001b[39m, extract_images: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_valid_pdf_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_filepath\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[0;32m     63\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m extract_images:\n",
      "\u001b[0;32m     64\u001b[0m             loader \u001b[38;5;241m=\u001b[39m PyMuPDFLoader(pdf_filepath, extract_images\u001b[38;5;241m=\u001b[39mextract_images)\n",
      "\n",
      "File \u001b[1;32mD:\\Shaukat ali khan\\programming\\AI-Projects\\langchain-projects\\langchain_codebase\\langchain_codebase\\codebase.py:25\u001b[0m, in \u001b[0;36mis_valid_pdf_path\u001b[1;34m(pdf_filepath)\u001b[0m\n",
      "\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_valid_pdf_path\u001b[39m(pdf_filepath):\n",
      "\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_valid_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_filepath\u001b[49m\u001b[43m)\u001b[49m:\n",
      "\u001b[0;32m     26\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pdf_filepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;32m     27\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m        \n",
      "\n",
      "File \u001b[1;32mD:\\Shaukat ali khan\\programming\\AI-Projects\\langchain-projects\\langchain_codebase\\langchain_codebase\\codebase.py:23\u001b[0m, in \u001b[0;36mis_valid_path\u001b[1;34m(path)\u001b[0m\n",
      "\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;32m---> 23\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPath doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist. Provided path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mException\u001b[0m: Path doesn't exist. Provided path: src\\books\\Physics9EM.pdf"
     ]
    }
   ],
   "source": [
    "docs = load_single_pdf(BOOK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_no = 0\n",
    "\n",
    "def find_Unit_index_and_get_required_content(page_no):\n",
    "    page_content = docs[page_no].page_content\n",
    "    Unit_index = page_content.find('Unit ')\n",
    "\n",
    "    if Unit_index > 20:\n",
    "        s_index = Unit_index - 20\n",
    "    else:\n",
    "        s_index = Unit_index\n",
    "\n",
    "    required_content = page_content[(s_index):(Unit_index + 20)]\n",
    "\n",
    "    return Unit_index, required_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking if all the pages have the string \"Unit \"\n",
    "\n",
    "# for page_no in range(len(docs)):\n",
    "#     Unit_index, content = find_Unit_index_and_get_required_content(page_no)\n",
    "#     print(f\"\\nPage no: {page_no}, Unit index: {Unit_index}\")\n",
    "\n",
    "# All of them have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def load_ollama_model(model: str = 'gemma2:2b'):\n",
    "    return OllamaLLM(model=model)\n",
    "\n",
    "def get_response_from_model(llm, prompt):\n",
    "    return llm.invoke(prompt)\n",
    "\n",
    "def get_quiz_generator_prompt():\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables = ['no_questions', 'book_content'],\n",
    "        template = QUIZ_GENERATOR_PROMPT\n",
    "    )\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocumentProcessor:\n",
    "    UNIT_WORD = \"Unit \"\n",
    "    EXTRA_CHARS_TO_EXTRACT_AROUND_UNIT_WORD = 20\n",
    "    UNIT_VAL_ENDING_VALS = [\":\", \"\\n\"]\n",
    "\n",
    "    def extract_details_from_docs_as_df(self, docs, book_name):\n",
    "        pages_with_no_unit_info = 0\n",
    "        book_data = {\n",
    "            'book_name': [],\n",
    "            'page_no': [],\n",
    "            'unit_no': [],\n",
    "            'content': []\n",
    "        }\n",
    "        for doc in docs:\n",
    "            page_no, unit_no, content = self.extract_page_no_unit_no_page_content_from_doc(doc)\n",
    "            book_data['page_no'].append(page_no)\n",
    "            book_data['unit_no'].append(unit_no)\n",
    "            book_data['content'].append(content)\n",
    "            book_data['book_name'].append(book_name)\n",
    "\n",
    "            if not unit_no.isnumeric():\n",
    "                pages_with_no_unit_info += 1\n",
    "\n",
    "        print(f\"Pages with no unit info: {pages_with_no_unit_info}\")\n",
    "        return pd.DataFrame(book_data)\n",
    "\n",
    "    def extract_page_no_unit_no_page_content_from_doc(self, doc):\n",
    "        page_no = doc.metadata['page']\n",
    "        page_content = doc.page_content\n",
    "        unit_no = self.extract_unit_no_from_content(page_content)\n",
    "\n",
    "        return (page_no, unit_no, page_content)\n",
    "\n",
    "    def extract_unit_no_from_content(self, content: str):\n",
    "        print(\"Extracting unit no...\")\n",
    "        chunk = self.extract_chunk_containing_unit_value(content)\n",
    "\n",
    "        unit_val_start_index = self.extract_unit_val_start_index(chunk)\n",
    "        unit_val_end_index = self.extract_unit_val_end_index(chunk)    \n",
    "\n",
    "        unit_val = chunk[unit_val_start_index:unit_val_end_index]\n",
    "        return unit_val\n",
    "\n",
    "    def extract_chunk_containing_unit_value(self, content: str):\n",
    "        unit_word_index_in_content = content.find(self.UNIT_WORD)\n",
    "\n",
    "        if self.is_found_invalid_index(unit_word_index_in_content):\n",
    "            return \"\"\n",
    "        \n",
    "        chunk_start_index = self.get_chunk_start_index(unit_word_index_in_content)\n",
    "        chunk_end_index = self.get_chunk_end_index(unit_word_index_in_content)\n",
    "\n",
    "        chunk = content[chunk_start_index:chunk_end_index]\n",
    "        return chunk\n",
    "\n",
    "    def get_chunk_start_index(self, unit_word_index):\n",
    "        if self.required_extra_chars_available_before_unit_word_index(unit_word_index):\n",
    "            chunk_start_index = unit_word_index - self.EXTRA_CHARS_TO_EXTRACT_AROUND_UNIT_WORD\n",
    "        else:\n",
    "            chunk_start_index = unit_word_index\n",
    "        return chunk_start_index\n",
    "\n",
    "    def required_extra_chars_available_before_unit_word_index(self, unit_word_index):\n",
    "        if unit_word_index > self.EXTRA_CHARS_TO_EXTRACT_AROUND_UNIT_WORD:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def get_chunk_end_index(self, unit_word_index):\n",
    "        unit_word_end_index = unit_word_index + len(self.UNIT_WORD)\n",
    "        chunk_end_index = unit_word_end_index + self.EXTRA_CHARS_TO_EXTRACT_AROUND_UNIT_WORD\n",
    "        \n",
    "        # catch: if required extra chars are not available after unit_word_end_index then while extracting chunk from the content, by default the chunk will end when the content will end. No matter if chunk_end_index is greater than the length of the content.\n",
    "        return chunk_end_index\n",
    "\n",
    "\n",
    "    def extract_unit_val_start_index(self, chunk: str):\n",
    "        unit_word_index_in_chunk = chunk.find(self.UNIT_WORD)\n",
    "        unit_val_start_index = unit_word_index_in_chunk + len(self.UNIT_WORD)\n",
    "        return unit_val_start_index\n",
    "\n",
    "\n",
    "    def extract_unit_val_end_index(self, chunk: str):\n",
    "        for val in self.UNIT_VAL_ENDING_VALS:\n",
    "            if val in chunk:\n",
    "                unit_val_end_index = chunk.find(val)\n",
    "                return unit_val_end_index\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        unit_val_end_index = len(chunk)\n",
    "        return unit_val_end_index\n",
    "\n",
    "\n",
    "    def is_found_invalid_index(self, index):\n",
    "        return True if (index == -1) else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages with no unit info: 5\n"
     ]
    }
   ],
   "source": [
    "# # checking number of docs with no unit info and saving the data\n",
    "# book_data = {\n",
    "#     'page_no': [],\n",
    "#     'unit_no': [],\n",
    "#     'content': []\n",
    "# }\n",
    "# pages_with_no_unit_info = 0\n",
    "\n",
    "# for doc in docs:\n",
    "#     page_no, unit_no, page_content = doc_processor.extract_page_no_unit_no_page_content_from_doc(doc)\n",
    "\n",
    "#     book_data['page_no'].append(page_no)\n",
    "#     book_data['unit_no'].append(unit_no)\n",
    "#     book_data['content'].append(content)\n",
    "    \n",
    "#     # print(unit_no)\n",
    "#     if not unit_no.isnumeric():\n",
    "#         pages_with_no_unit_info += 1\n",
    "\n",
    "# print(f\"Pages with no unit info: {pages_with_no_unit_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_processor = DocumentProcessor()\n",
    "    \n",
    "def process_book_pdf_and_save_df(book_pdf_path):\n",
    "    path_separator = detect_path_separator_in_path(book_pdf_path)\n",
    "    book_name = book_pdf_path.split(path_separator)[-1].split(\".\")[0]\n",
    "    book_save_path = book_name + \".csv\"\n",
    "\n",
    "    df = extract_details_from_book_pdf_path_as_df(book_pdf_path, book_name)\n",
    "    df.to_csv(book_save_path, index=False)\n",
    "\n",
    "    print(f\"Book saved as: {book_save_path}\")\n",
    "\n",
    "def extract_details_from_book_pdf_path_as_df(book_pdf_path, book_name: str):\n",
    "    if is_valid_pdf_path(book_pdf_path):\n",
    "        docs = load_single_pdf(book_pdf_path)\n",
    "        df = doc_processor.extract_details_from_docs_as_df(docs, book_name)\n",
    "        return df\n",
    "\n",
    "def detect_path_separator_in_path(path):\n",
    "    if '\\\\' in path:\n",
    "        path_separator = \"\\\\\"\n",
    "    else:\n",
    "        path_separator = '/'\n",
    "\n",
    "    return path_separator\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_book_pdf_and_save_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n",
      "\u001b[1;32m----> 1\u001b[0m \u001b[43mprocess_book_pdf_and_save_df\u001b[49m(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msrc\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbooks\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mEnglish 9.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_book_pdf_and_save_df' is not defined"
     ]
    }
   ],
   "source": [
    "process_book_pdf_and_save_df(r\"src\\books\\English 9.pdf\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
